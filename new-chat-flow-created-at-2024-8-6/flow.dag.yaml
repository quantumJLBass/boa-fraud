$schema: https://azuremlschemas.azureedge.net/promptflow/latest/Flow.schema.json
environment:
  python_requirements_txt: requirements.txt
inputs:
  chat_history:
    type: list
    is_chat_history: true
    default: []
  question:
    type: string
    is_chat_input: true
outputs:
  answer:
    type: string
    reference: ${chat.output}
    is_chat_output: true
nodes:
- name: chat
  type: llm
  source:
    type: code
    path: chat.jinja2
  inputs:
    deployment_name: gpt-35-turbo
    max_tokens: "256"
    temperature: "0.7"
    chat_history: ${inputs.chat_history}
    question: ${inputs.question}
  connection: open_ai_connection
  api: chat
- name: LLMLingua_Prompt_Compression_Tool_xct2
  type: python
  source:
    type: package
    tool: llmlingua_promptflow.tools.llmlingua.prompt_compress
  inputs: {}
  aggregation: true
- name: Index_Lookup_wvwo
  type: python
  source:
    type: package
    tool: promptflow_vectordb.tool.common_index_lookup.search
  inputs: {}
  aggregation: true
- name: Open_Model_LLM_jpcb
  type: custom_llm
  source:
    type: package_with_prompt
    tool: promptflow.tools.open_model_llm.OpenModelLLM.call
    path: Open_Model_LLM_jpcb.jinja2
  inputs: {}
- name: Open_Model_LLM_1vtf
  type: custom_llm
  source:
    type: package_with_prompt
    tool: promptflow.tools.open_model_llm.OpenModelLLM.call
    path: Open_Model_LLM_1vtf.jinja2
  inputs: {}
